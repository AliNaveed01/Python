{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 18:23:39.025506: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-11 18:23:42.856641: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from ultralytics import YOLO\n",
    "# import cv2\n",
    "\n",
    "# def filter_images_with_objects(yolo_model, input_folder, output_folder, targetclasses):\n",
    "#     # Load the YOLO model\n",
    "#     model = YOLO(yolo_model)\n",
    "\n",
    "#     # Create the output folder if it doesn't exist\n",
    "#     if not os.path.exists(output_folder):\n",
    "#         os.makedirs(output_folder)\n",
    "\n",
    "#     for filename in os.listdir(input_folder):\n",
    "#         if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "#             image_path = os.path.join(input_folder, filename)\n",
    "#             image = cv2.imread(image_path)\n",
    "\n",
    "#             # Run the YOLO model on the image\n",
    "#             results = model(image)\n",
    "\n",
    "#             # Check if the desired object is detected\n",
    "#             for result in results:\n",
    "#                 found = False\n",
    "#                 for bbox in result.boxes.data:\n",
    "#                     # bbox format: [x_min, y_min, x_max, y_max, confidence, class_id]\n",
    "#                     class_id = int(bbox[5])\n",
    "#                     if model.names[class_id] in targetclasses:\n",
    "#                         found = True\n",
    "#                         # Draw bounding box\n",
    "#                         x_min, y_min, x_max, y_max = map(int, bbox[:4])\n",
    "#                         cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "#                         cv2.putText(image, model.names[class_id], (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "#                 if found:\n",
    "#                     # Save the image with annotations\n",
    "#                     output_path = os.path.join(output_folder, filename)\n",
    "#                     print(f\"Saving annotated image to: {output_path}\")\n",
    "#                     cv2.imwrite(output_path, image)\n",
    "#                     break\n",
    "\n",
    "# # Example usage\n",
    "# yolo_model = 'yolov8x.pt'  # You can specify your model file path here\n",
    "# input_folder = 'Data Collection'\n",
    "# output_folder = 'Filtered Data Collection'\n",
    "# targetclasses = ['Military Vehicle', 'truck', 'car', 'boat', 'SUV', 'tank', 'Armored Vehicle', 'helicopter', 'aircraft', 'person', 'bus']\n",
    "\n",
    "# filter_images_with_objects(yolo_model, input_folder, output_folder, targetclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 15976.5ms\n",
      "Speed: 16.6ms preprocess, 15976.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15542.2ms\n",
      "Speed: 11.0ms preprocess, 15542.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15174.1ms\n",
      "Speed: 10.8ms preprocess, 15174.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15344.6ms\n",
      "Speed: 12.3ms preprocess, 15344.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15241.9ms\n",
      "Speed: 12.1ms preprocess, 15241.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 18200.2ms\n",
      "Speed: 13.8ms preprocess, 18200.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 14683.8ms\n",
      "Speed: 10.3ms preprocess, 14683.8ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 14832.0ms\n",
      "Speed: 6.2ms preprocess, 14832.0ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Saved Filtered Data Collection/880f65fb-2a61-482f-ac9d-1e8ab487f8ee.jpg and its annotations.\n",
      "\n",
      "0: 384x640 1 train, 14499.5ms\n",
      "Speed: 12.1ms preprocess, 14499.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16972.8ms\n",
      "Speed: 13.0ms preprocess, 16972.8ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15096.5ms\n",
      "Speed: 12.7ms preprocess, 15096.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14914.2ms\n",
      "Speed: 11.6ms preprocess, 14914.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14843.6ms\n",
      "Speed: 11.6ms preprocess, 14843.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15396.6ms\n",
      "Speed: 14.3ms preprocess, 15396.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 wine glass, 15000.7ms\n",
      "Speed: 10.7ms preprocess, 15000.7ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15124.2ms\n",
      "Speed: 10.6ms preprocess, 15124.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 14772.8ms\n",
      "Speed: 17.3ms preprocess, 14772.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Saved Filtered Data Collection/4fa3e437-4da1-4edd-bada-30bf5e0f0767.jpg and its annotations.\n",
      "\n",
      "0: 384x640 (no detections), 14486.1ms\n",
      "Speed: 10.6ms preprocess, 14486.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 14798.7ms\n",
      "Speed: 10.3ms preprocess, 14798.7ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14974.0ms\n",
      "Speed: 13.9ms preprocess, 14974.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 wine glass, 15679.1ms\n",
      "Speed: 10.8ms preprocess, 15679.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15281.2ms\n",
      "Speed: 13.3ms preprocess, 15281.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15444.2ms\n",
      "Speed: 8.9ms preprocess, 15444.2ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15618.7ms\n",
      "Speed: 13.6ms preprocess, 15618.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15527.3ms\n",
      "Speed: 11.1ms preprocess, 15527.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15470.6ms\n",
      "Speed: 13.8ms preprocess, 15470.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15130.5ms\n",
      "Speed: 6.5ms preprocess, 15130.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15811.2ms\n",
      "Speed: 11.4ms preprocess, 15811.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15710.0ms\n",
      "Speed: 10.9ms preprocess, 15710.0ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16175.4ms\n",
      "Speed: 13.7ms preprocess, 16175.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15558.1ms\n",
      "Speed: 10.7ms preprocess, 15558.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 15277.9ms\n",
      "Speed: 10.9ms preprocess, 15277.9ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Saved Filtered Data Collection/df12126b-442c-4fd2-a338-886f3d58207e.jpg and its annotations.\n",
      "\n",
      "0: 384x640 1 wine glass, 15477.3ms\n",
      "Speed: 8.0ms preprocess, 15477.3ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15407.9ms\n",
      "Speed: 11.5ms preprocess, 15407.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 16057.3ms\n",
      "Speed: 11.9ms preprocess, 16057.3ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15374.0ms\n",
      "Speed: 12.1ms preprocess, 15374.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15440.2ms\n",
      "Speed: 13.5ms preprocess, 15440.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15738.9ms\n",
      "Speed: 14.5ms preprocess, 15738.9ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 wine glass, 16098.8ms\n",
      "Speed: 11.7ms preprocess, 16098.8ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15969.7ms\n",
      "Speed: 10.9ms preprocess, 15969.7ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 wine glass, 15829.7ms\n",
      "Speed: 10.0ms preprocess, 15829.7ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15195.0ms\n",
      "Speed: 13.0ms preprocess, 15195.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15558.3ms\n",
      "Speed: 10.5ms preprocess, 15558.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15656.3ms\n",
      "Speed: 13.6ms preprocess, 15656.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 20357.7ms\n",
      "Speed: 12.6ms preprocess, 20357.7ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 18217.1ms\n",
      "Speed: 14.7ms preprocess, 18217.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15866.9ms\n",
      "Speed: 10.5ms preprocess, 15866.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15354.3ms\n",
      "Speed: 11.1ms preprocess, 15354.3ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 18225.2ms\n",
      "Speed: 13.3ms preprocess, 18225.2ms inference, 9.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 17125.0ms\n",
      "Speed: 12.4ms preprocess, 17125.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15564.8ms\n",
      "Speed: 8.1ms preprocess, 15564.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import uuid\n",
    "\n",
    "def filter_and_annotate_images(yolo_model, input_folder, output_folder, target_classes):\n",
    "    # Load the YOLO model\n",
    "    model = YOLO(yolo_model)\n",
    "\n",
    "    # Create the output folders if they don't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    annotations_folder = os.path.join(output_folder, 'annotations')\n",
    "    if not os.path.exists(annotations_folder):\n",
    "        os.makedirs(annotations_folder)\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            image_path = os.path.join(input_folder, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            height, width = image.shape[:2]\n",
    "\n",
    "            # Run the YOLO model on the image\n",
    "            results = model(image)\n",
    "\n",
    "            for result in results:\n",
    "                found = False\n",
    "                annotation_content = []\n",
    "                for bbox in result.boxes.data:\n",
    "                    # bbox format: [x_min, y_min, x_max, y_max, confidence, class_id]\n",
    "                    class_id = int(bbox[5])\n",
    "                    if model.names[class_id] in target_classes:\n",
    "                        found = True\n",
    "                        x_min, y_min, x_max, y_max = map(int, bbox[:4])\n",
    "                        \n",
    "                        # Calculate YOLO format values\n",
    "                        x_center = (x_min + x_max) / 2.0 / width\n",
    "                        y_center = (y_min + y_max) / 2.0 / height\n",
    "                        box_width = (x_max - x_min) / width\n",
    "                        box_height = (y_max - y_min) / height\n",
    "                        \n",
    "                        annotation_content.append(f\"{class_id} {x_center} {y_center} {box_width} {box_height}\")\n",
    "                \n",
    "                if found:\n",
    "                    # Generate a unique filename\n",
    "                    unique_filename = str(uuid.uuid4())\n",
    "                    image_output_path = os.path.join(output_folder, f\"{unique_filename}.jpg\")\n",
    "                    annotation_output_path = os.path.join(annotations_folder, f\"{unique_filename}.txt\")\n",
    "\n",
    "                    # Save the image\n",
    "                    cv2.imwrite(image_output_path, image)\n",
    "                    # Save the annotation\n",
    "                    with open(annotation_output_path, 'w') as f:\n",
    "                        f.write(\"\\n\".join(annotation_content))\n",
    "                    print(f\"Saved {image_output_path} and its annotations.\")\n",
    "\n",
    "# Example usage\n",
    "yolo_model = 'yolov8x.pt'  # You can specify your model file path here\n",
    "input_folder = 'extracted_frames_from_v7'\n",
    "output_folder = 'Filtered Data Collection'\n",
    "target_classes = ['car','bus','truck','boat','bus','airplane']\n",
    "\n",
    "filter_and_annotate_images(yolo_model, input_folder, output_folder, target_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
